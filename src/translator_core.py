import asyncio
import copy
import logging
import PIL.Image
from bs4 import BeautifulSoup
from chunker import HtmlChunker
import re 
import time
import PIL
import io
import ast
from google.genai import types
import html

# Constants
MAX_RETRIES = 3

def parse_retry_delay_from_error(error, extra_seconds=2) -> int:
    """
    ì£¼ì–´ì§„ ì—ëŸ¬ ë©”ì‹œì§€ì—ì„œ ì¬ì‹œë„ ì§€ì—°ì‹œê°„(ì´ˆ)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ì—ëŸ¬ ë©”ì‹œì§€ì— "retry after <ìˆ«ì>" í˜•íƒœê°€ ìˆë‹¤ë©´ í•´ë‹¹ ìˆ«ìë¥¼ ë°˜í™˜í•˜ê³ ,
    ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ 10ì´ˆë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    error_str = str(error)
    start_idx = error_str.find('{')
    if start_idx == -1:
        return 0  # JSON ë¶€ë¶„ ì—†ìŒ
    
    dict_str = error_str[start_idx:]
    retry_seconds = 0

    try:
        # JSONì´ ì•„ë‹ˆë¼ Python dictì²˜ëŸ¼ ìƒê¸´ ë¬¸ìì—´ì´ë¯€ë¡œ literal_eval ì‚¬ìš©
        err_data = ast.literal_eval(dict_str)
        details = err_data.get("error", {}).get("details", [])
        for detail in details:
            if detail.get("@type") == "type.googleapis.com/google.rpc.RetryInfo":
                retry_str = detail.get("retryDelay", "")  # ì˜ˆ: "39s"
                match = re.match(r"(\d+)s", retry_str)
                if match:
                    retry_seconds = int(match.group(1))
                    break
    except Exception as e:
        print(f"[WARN] retryDelay íŒŒì‹± ì‹¤íŒ¨: {e}")
        return 10

    return retry_seconds + extra_seconds if retry_seconds > 0 else 0

# Setup logger
logger = logging.getLogger(__name__)
if not logger.handlers:
    handler_stream = logging.StreamHandler()
    handler_file = logging.FileHandler('translator.log', encoding='utf-8')
    formatter = logging.Formatter('[%(asctime)s] %(levelname)s:%(name)s: %(message)s')
    handler_stream.setFormatter(formatter)
    handler_file.setFormatter(formatter)
    logger.addHandler(handler_stream)
    logger.addHandler(handler_file)
    logger.setLevel(logging.INFO)

client = None
max_chunk_size = 3000
llm_model = 'gemini-2.0-flash'
custom_prompt = ''
llm_delay = 0.0
japanese_char_threshold = 15
language = 'Japanese'

def set_client(client_instance):
    """Sets the global client instance for API calls."""
    global client
    client = client_instance

def set_llm_model(name):
    global llm_model
    llm_model = name

def set_chunk_size(size):
    global max_chunk_size
    max_chunk_size = size

def set_custom_prompt(prompt):
    global custom_prompt
    if prompt:
        custom_prompt = prompt

def set_llm_delay(time):
    global llm_delay
    llm_delay = time

def set_japanese_char_threshold(threshold):
    global japanese_char_threshold
    japanese_char_threshold = threshold
    
def set_language(lang):
    global language
    language = lang

def clean_gemini_response(response_text: str) -> str:
    """
    Cleans the Gemini API response by stripping markdown formatting.
    """
    text = response_text.strip()
    if text.startswith("```html"):
        text = text[7:].strip()
    elif text.startswith("```"):
        text = text[3:].strip()
    if text.startswith("### html"):
        text = text[8:].strip()
    if text.startswith("```html"):
        text = text[7:].strip()
    elif text.startswith("```"):
        text = text[3:].strip()
    if text.endswith("```"):
        text = text[:-3].strip()
    return text

def detect_repeats(text: str, min_repeat: int = 4, max_unit_len: int = 10) -> str:
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ ë°˜ë³µë˜ëŠ” ë¬¸ìì—´ì„ <repeat time="N">...<repeat> í˜•íƒœë¡œ ê°ì‹¸ì„œ ë°˜í™˜
    """
    i = 0
    result = ""
    text_len = len(text)

    while i < text_len:
        replaced = False
        for unit_len in range(max_unit_len, 0, -1):
            unit = text[i:i + unit_len]
            if not unit or i + unit_len > text_len:
                continue

            repeat_count = 1
            while text[i + repeat_count * unit_len: i + (repeat_count + 1) * unit_len] == unit:
                repeat_count += 1

            if repeat_count >= min_repeat:
                result += f'<repeat time="{repeat_count}">{unit}</repeat>'
                i += unit_len * repeat_count
                replaced = True
                break

        if not replaced:
            result += text[i]
            i += 1

    return result

def wrap_repeats_in_paragraphs_and_headers(html: str, min_repeat: int = 4) -> str:
    """
    HTMLì—ì„œ <p> ë° <h1>~<h6> íƒœê·¸ ì•ˆì˜ í…ìŠ¤íŠ¸ì—ë§Œ <repeat> íƒœê·¸ ì ìš©
    """
    soup = BeautifulSoup(html, "lxml-xml")
    target_tags = [f"h{i}" for i in range(1, 7)] + ["p"]

    for tag in soup.find_all(target_tags):
        for child in tag.find_all(string=True, recursive=True):
            original = str(child)
            replaced = detect_repeats(original, min_repeat=min_repeat)
            if replaced != original:
                child.replace_with(replaced)

    return str(soup)


def restore_repeat_tags_translated(html_content: str) -> str:
    """
    HTML ë‚´ ì´ìŠ¤ì¼€ì´í”„ëœ <repeat time="N">...</repeat> íƒœê·¸ë¥¼ ì‹¤ì œ ë°˜ë³µ ë¬¸ìì—´ë¡œ ë³µì›
    """
    # 1. HTML ë¬¸ìì—´ ë‚´ ì´ìŠ¤ì¼€ì´í”„ëœ ë¬¸ì(&lt;, &gt; ë“±)ë¥¼ ì‹¤ì œ ë¬¸ìë¡œ ë³€í™˜
    unescaped_html = html.unescape(html_content)
    
    # 2. ì •ê·œì‹ íŒ¨í„´: <repeat time="N">...</repeat> (ë‹¨ìˆœ ì¤‘ì²© ì—†ì´ ì²˜ë¦¬)
    pattern = re.compile(r'<repeat\s+time="(\d+)">(.*?)</repeat>', re.DOTALL)
    
    # ë°˜ë³µì ìœ¼ë¡œ ì°¾ì•„ì„œ êµì²´ (íƒœê·¸ ì•ˆì— ë˜ repeatê°€ ìˆì„ ê²½ìš°ì—ë„ ì²˜ë¦¬)
    while True:
        match = pattern.search(unescaped_html)
        if not match:
            break
        
        count = int(match.group(1))
        content = match.group(2)
        repeated_content = content * count
        
        unescaped_html = unescaped_html[:match.start()] + repeated_content + unescaped_html[match.end():]
    
    return unescaped_html

def count_closing_tags(html: str, tags: list[str]) -> dict:
    """
    HTML ë¬¸ìì—´ì—ì„œ ì§€ì •ëœ íƒœê·¸ë“¤ì˜ ë‹«ëŠ” íƒœê·¸(</tag>) ê°œìˆ˜ë¥¼ ë°˜í™˜
    """
    counts = {}
    for tag in tags:
        closing_pattern = f"</{tag}>"
        counts[tag] = html.count(closing_pattern)
    return counts

def translate_chunk_for_enhance(html_fragment, language):
    set_language(language)
    processed_html = detect_repeats(html_fragment)
    prompt = (
        "ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¼ì´íŠ¸ë…¸ë²¨ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì— ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ëŠ” ì´ë¯¸ í•œêµ­ì–´ë¡œ ë²ˆì—­ëœ ìƒíƒœì´ì§€ë§Œ, ì¼ë¶€ ì™¸êµ­ì–´(ì¼ë³¸ì–´, ì˜ì–´, í‚¤ë¦´ë¬¸ì ë“±)ê°€ ê·¸ëŒ€ë¡œ ë‚¨ì•„ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"

        "ğŸ“ ë²ˆì—­ ì§€ì¹¨:\n"
        "- **ì´ë¯¸ í•œêµ­ì–´ë¡œ ë²ˆì—­ëœ ë¬¸ì¥ì€ ìˆ˜ì •í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.**\n"
        "- **í•œêµ­ì–´ê°€ ì•„ë‹Œ í…ìŠ¤íŠ¸ë§Œ ìì—°ìŠ¤ëŸ½ê³  ë¬¸í•™ì ì¸ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì‹­ì‹œì˜¤.**\n"
        "- **ì¶œë ¥ì—ëŠ” ì˜¤ì§ í•œêµ­ì–´ë§Œ í¬í•¨ë˜ì–´ì•¼ í•˜ë©°, ì™¸êµ­ì–´ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.**\n"
        "- **ì¼ë³¸ì–´/ì˜ì–´ ì›ë¬¸ì„ ë³‘ê¸°í•˜ê±°ë‚˜ 'â†’'ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•˜ì§€ ë§ˆì‹­ì‹œì˜¤.**\n"
        "- ì„¤ëª…, ì£¼ì„, ë§ˆí¬ë‹¤ìš´ ë“±ì˜ ì¶œë ¥ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.\n"
        "- ë²ˆì—­í•  ì™¸êµ­ì–´ê°€ ì—†ë‹¤ë©´ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ì‹­ì‹œì˜¤.\n\n"

        "âŒ ì˜ëª»ëœ ì˜ˆì‹œ:\n"
        "ç”°ä¸­â€¦â€¦ï¼Ÿ â†’ ë‹¤ë‚˜ì¹´......?\n"
        "Tanaka......?: ë‹¤ë‚˜ì¹´......?\n\n"

        "âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ:\n"
        "ë‹¤ë‚˜ì¹´......?\n\n"

        "ë‹¤ìŒ ê¸€ì„ ê²€í† í•˜ì—¬ ì™¸êµ­ì–´ë§Œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì‹­ì‹œì˜¤. ì´ë¯¸ ë²ˆì—­ëœ í•œêµ­ì–´ëŠ” ë³€ê²½í•˜ì§€ ë§ˆì‹­ì‹œì˜¤:\n\n"
        + processed_html
    )
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            response = client.models.generate_content(
                model=llm_model,
                contents=prompt,
                config=types.GenerateContentConfig(
                max_output_tokens=8192 if max_chunk_size < 8192 else max_chunk_size,
                frequency_penalty=0.5,
            ),
            )
            output = response.text.strip()
            output = clean_gemini_response(output)
            output = restore_repeat_tags_translated(output)
            
            logger.info(
                f"Translation result:\n"
                f"--- Input HTML ---\n{html_fragment}\n"
                f"--- Output HTML ---\n{output}"
            )

            if not output:
                raise ValueError("Empty or non-HTML response from Gemini for translation.")
            time.sleep(llm_delay)
            return output
        except Exception as e:
            logger.error(f"translate_chunk_for_enhance - Error on attempt {attempt}: {e}")
            if "429" in str(e) or "Resource exhausted" in str(e):
                attempt -= 1
                delay = parse_retry_delay_from_error(e)
                logger.info(f"429 error detected in translate_chunk_for_enhance, retrying after {delay} seconds.")
                time.sleep(delay)
            else:
                time.sleep(5 * attempt)
    logger.error("translate_chunk_for_enhance - Final failure after MAX_RETRIES attempts.")
    raise Exception("Translation failed in translate_chunk_for_enhance.")

def translate_chunk_with_html(html_fragment, chapter_index, chunk_index, language):
    """
    Translates a chunk of HTML from Japanese to Korean using the Gemini API.
    Raises an exception if the translation fails.
    """
    set_language(language)

    preprocessed_html = wrap_repeats_in_paragraphs_and_headers(html_fragment)

    prompt = (
        "**ì¤‘ìš”:** ë°˜ë“œì‹œ **ìˆœìˆ˜í•˜ê²Œ ë²ˆì—­ëœ HTMLë§Œ** ë°˜í™˜í•˜ì‹­ì‹œì˜¤. ì„¤ëª…, ì£¼ì„, ì½”ë“œ ë¸”ë¡, ê·¸ ì™¸ ë¶€ê°€ì ì¸ ë‚´ìš©ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.\n\n"

        f"ë‹¹ì‹ ì€ {language} ë¼ì´íŠ¸ë…¸ë²¨ ì „ë¬¸ ë²ˆì—­ê°€ì´ë©°, {language}ì—ì„œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì¼ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. "
        "ë²ˆì—­ì€ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš°ë©° ê°ì • í‘œí˜„ì´ í’ë¶€í•´ì•¼ í•˜ë©°, êµ­ë‚´ ì •ì‹ ì¶œê°„ì— ì í•©í•œ ìˆ˜ì¤€ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n\n"

        "ğŸ¯ ë²ˆì—­ ì§€ì¹¨:\n"
        "- ì›ë¬¸ì˜ ì–´ì¡°, ë¬¸í•™ì  ë‰˜ì•™ìŠ¤, ëŒ€í™”ì²´ ìŠ¤íƒ€ì¼ì„ ìµœëŒ€í•œ ìœ ì§€í•˜ì‹­ì‹œì˜¤.\n"
        "- ëª°ì…ê° ìˆê³  ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ í‘œí˜„ì„ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.\n\n"

        "âš ï¸ HTML ë° í˜•ì‹ ê´€ë ¨ ê·œì¹™:\n"
        "- HTML íƒœê·¸, êµ¬ì¡°, ì†ì„±(`<p>`, `<img>`, `<repeat>` `class` ë“±)ì€ ì ˆëŒ€ ìˆ˜ì •, ì œê±°, ì¬ë°°ì—´í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.\n"
        "- íŒŒì¼ ê²½ë¡œ, ì´ë¯¸ì§€ alt í…ìŠ¤íŠ¸, href, class ì´ë¦„, ë©”íƒ€ë°ì´í„° ë“± **ë³´ì´ì§€ ì•ŠëŠ” ì •ë³´ëŠ” ë²ˆì—­í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.**\n"
        f"- ìµœì¢… ê²°ê³¼ì— {language} í…ìŠ¤íŠ¸ê°€ ë‚¨ì•„ ìˆì–´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.\n"
        "- ë²ˆì—­í•  ì™¸êµ­ì–´ í…ìŠ¤íŠ¸ê°€ ì—†ë‹¤ë©´, ì›ë³¸ HTMLì„ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ì‹­ì‹œì˜¤.\n\n"

        + custom_prompt +

        "\nì´ì œ ë‹¤ìŒ HTMLì„ ê²€í† í•˜ì—¬ ë²ˆì—­ì„ ìˆ˜í–‰í•˜ì‹­ì‹œì˜¤:\n\n" + preprocessed_html
    )

    response = client.models.generate_content(
        model=llm_model,
        contents=prompt,
        config=types.GenerateContentConfig(
            top_k=50,
            top_p=0.85,
            temperature=1.8,
            max_output_tokens=8192 if max_chunk_size < 8192 else max_chunk_size,
            frequency_penalty=0.5,
        ),
    )
    output = response.text.strip()
    output = clean_gemini_response(output)

    output = restore_repeat_tags_translated(output)

    logger.info(
        f"[CH{chapter_index}][CHUNK{chunk_index}] Translation result:\n"
        f"--- Input HTML ---\n{html_fragment}\n"
        f"--- Preprocessed HTML ---\n{preprocessed_html}\n"
        f"--- Output HTML ---\n{output}"
    )

    input_tag_counts = count_closing_tags(html_fragment, ["p"] + [f"h{i}" for i in range(1, 7)])
    output_tag_counts = count_closing_tags(output, ["p"] + [f"h{i}" for i in range(1, 7)])

    if input_tag_counts["p"] != output_tag_counts["p"]:
        raise ValueError(f"<p> íƒœê·¸ ê°œìˆ˜ ë¶ˆì¼ì¹˜: input={input_tag_counts['p']} / output={output_tag_counts['p']}")

    input_h_total = sum(input_tag_counts[f"h{i}"] for i in range(1, 7))
    output_h_total = sum(output_tag_counts[f"h{i}"] for i in range(1, 7))
    if input_h_total != output_h_total:
        raise ValueError(f"<h1>~<h6> íƒœê·¸ ì´ ê°œìˆ˜ ë¶ˆì¼ì¹˜: input={input_h_total} / output={output_h_total}")

    if not output or "<" not in output:
        error_message = f"Empty or non-HTML response from Gemini for chapter {chapter_index}, chunk {chunk_index}."
        logger.error(error_message)
        raise ValueError(error_message)

    time.sleep(llm_delay)
    return output

def annotate_image(img_bytes, language):
    set_language(language)
    prompt = (
        "ë‹¹ì‹ ì€ ì´ë¯¸ì§€ ì†ì— í¬í•¨ëœ ì½ì„ ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ í™•ì¸í•˜ê²Œ ë©ë‹ˆë‹¤.\n"
        "ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ëª¨ë“  ì½ì„ ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n\n"

        "ğŸ“ ë²ˆì—­ ì§€ì¹¨:\n"
        "- ì´ë¯¸ì§€ì— **ë³´ì´ëŠ” í…ìŠ¤íŠ¸ë§Œ** ë²ˆì—­í•˜ì‹­ì‹œì˜¤.\n"
        "- í•œêµ­ì–´ ì›ì–´ë¯¼ì´ ì½ê¸°ì— ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ì„ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.\n"
        "- ì¶œë ¥ì—ëŠ” **í•œêµ­ì–´ë§Œ í¬í•¨**ë˜ì–´ì•¼ í•˜ë©°, ì™¸êµ­ì–´ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.\n"
        "- ì„¤ëª…, ì£¼ì„, ë§ˆí¬ë‹¤ìš´ ë“±ì˜ í˜•ì‹ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.\n\n"

        "ì˜¤ì§ ë²ˆì—­ëœ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤."
    )
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            response = client.models.generate_content(
                model="gemini-2.0-flash",
                contents=[
                    prompt,
                    PIL.Image.open(io.BytesIO(img_bytes))
                ],
                config=types.GenerateContentConfig(
                top_k= 50,
                top_p= 0.85,
                temperature= 0.8,
                max_output_tokens=8192 if max_chunk_size < 8192 else max_chunk_size,
                frequency_penalty=0.5,
                ),
            )
            output_text = response.text.strip()
            logger.info(f"--- Output Annotation ---\n{output_text}")
            return output_text
        except Exception as e:
            logger.error(f"annotate_image - Error on attempt {attempt}: {e}")
            if "429" in str(e) or "Resource exhausted" in str(e):
                attempt -= 1
                delay = parse_retry_delay_from_error(e)
                logger.info(f"429 error detected in annotate_image, retrying after {delay} seconds.")
                time.sleep(delay)
            else:
                time.sleep(5 * attempt)
    logger.error("annotate_image - Final failure after MAX_RETRIES attempts.")
    raise Exception("Annotate image failed.")

async def async_translate_chunk(html_fragment, chapter_index, chunk_index, semaphore, executor):
    """
    Asynchronously translates an HTML chunk with retry logic.
    """
    for attempt in range(1, MAX_RETRIES + 1):
        async with semaphore:
            try:
                loop = asyncio.get_running_loop()
                result = await loop.run_in_executor(
                    executor,
                    translate_chunk_with_html,
                    html_fragment,
                    chapter_index,
                    chunk_index,
                    language
                )
                # ë²ˆì—­ ê²°ê³¼ì—ì„œ HTML íƒœê·¸ë¥¼ ì œì™¸í•œ ë³´ì´ëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œ
                soup = BeautifulSoup(result, "lxml-xml")
                visible_text = soup.get_text()
                japanese_chars = re.findall(r'[\u3040-\u30FF\u31F0-\u31FF\u4E00-\u9FFF]', visible_text)
                cyrill_chars = re.findall(r'[\u0400-\u04FF\u0500-\u052F]', visible_text)
                thai_chars = re.findall(r'[\u0E00-\u0E7F]', visible_text)
                arabic_chars = re.findall(r'[\u0600-\u06FF\u0750-\u077F]', visible_text)
                hebrew_chars = re.findall(r'[\u0590-\u05FF]', visible_text)
                devanagari_chars = re.findall(r'[\u0900-\u097F]', visible_text)
                greek_chars = re.findall(r'[\u0370-\u03FF]', visible_text)
                
                if japanese_chars or cyrill_chars or thai_chars or arabic_chars or hebrew_chars or devanagari_chars or greek_chars:
                    foreign_chars = japanese_chars + cyrill_chars + thai_chars + arabic_chars + hebrew_chars + devanagari_chars + greek_chars
                else:
                    foreign_chars = []
                count = len(foreign_chars)
                if count >= japanese_char_threshold:
                    if attempt < MAX_RETRIES:
                        raise Exception(
                            f"Translation result contains {count} Japanese characters on attempt {attempt}, triggering a retry."
                        )
                    else:
                        logger.warning(
                            f"[{chapter_index}-{chunk_index}] Last attempt result contains {count} Japanese characters. Using it."
                        )
                return result
            except Exception as e:
                logger.error(f"[{chapter_index}-{chunk_index}] Error on attempt {attempt}: {e}")
                if "429" in str(e) or "Resource exhausted" in str(e):
                    attempt -= 1
                    delay = parse_retry_delay_from_error(e)
                    logger.info(f"[{chapter_index}-{chunk_index}] 429 error detected, retrying after {delay} seconds.")
                    await asyncio.sleep(delay)
                else:
                    await asyncio.sleep(5 * attempt)
            finally:
                await asyncio.sleep(llm_delay)
    logger.error(f"[{chapter_index}-{chunk_index}] Final failure after {MAX_RETRIES} attempts. Returning original fragment.")
    return html_fragment

async def translate_chapter_async(html, chapter_index, executor, semaphore):
    """
    Translates an entire chapter asynchronously by splitting it into chunks,
    translating each chunk concurrently, and recombining the results.
    """
    soup = BeautifulSoup(html, 'lxml-xml')
    head = soup.head
    body = soup.body if soup.body else soup

    # Use HtmlChunker to split the body into manageable chunks.
    chunker = HtmlChunker(max_chars=max_chunk_size)
    chunks = chunker.chunk_body_preserving_structure(body)

    tasks = []
    for chunk_index, chunk in enumerate(chunks):
        html_fragment = str(chunk)
        tasks.append(
            async_translate_chunk(html_fragment, chapter_index, chunk_index, semaphore, executor)
        )
    translated_chunks = await asyncio.gather(*tasks)

    new_soup = BeautifulSoup("", "lxml-xml")
    html_tag = new_soup.new_tag("html")
    new_soup.append(html_tag)
    if head:
        html_tag.append(copy.copy(head))
    new_body = new_soup.new_tag("body")
    for translated_chunk in translated_chunks:
        chunk_soup = BeautifulSoup(translated_chunk, "lxml-xml")
        for content in list(chunk_soup.contents):
            new_body.append(content)
    html_tag.append(new_body)
    return str(new_soup)
